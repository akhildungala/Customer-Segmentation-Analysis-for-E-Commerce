# -*- coding: utf-8 -*-
"""preprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17zFYpL5mzcSf2OYc9dldpeEBy21j1ILA
"""

# Check Python version
!python --version

# Install required libraries (if not already installed)
!pip install pandas numpy scikit-learn seaborn matplotlib

# Verify installations
import pandas as pd
import numpy as np
import sklearn
import seaborn as sns
import matplotlib
import sqlite3

print("Pandas version:", pd. __version__)
print("NumPy version:", np. __version__)
print("Scikit-learn version:", sklearn.__version__)
print("Seaborn version:", sns.__version__)
print("Matplotlib version:", matplotlib.__version__)
print("SQLite3 version:", sqlite3.sqlite_version)

# Load and preview the dataset
import pandas as pd

# Adjust the file path if necessary (e.g., if uploaded manually, itâ€™s in /content)
df = pd.read_csv('/content/OnlineRetail.csv', encoding='latin1')
df.head()  # Display the first 5 rows

import pandas as pd
import numpy as np
import os

def load_and_clean_data(file_path):
    """
    Load and clean the Online Retail dataset.
    """
    try:
        # Check if file exists
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Dataset file not found at: {file_path}")

        # Load dataset
        df = pd.read_csv(file_path, encoding='ISO-8859-1')
        print(f"Dataset loaded successfully. Shape: {df.shape}")

        # Handle missing values
        initial_rows = df.shape[0]
        df = df.dropna(subset=['CustomerID', 'InvoiceNo', 'Quantity', 'UnitPrice'])
        print(f"Rows after removing missing values: {df.shape[0]} ({initial_rows - df.shape[0]} rows dropped)")

        # Remove negative quantities and prices (likely errors or refunds)
        df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]
        print(f"Rows after removing negative quantities/prices: {df.shape[0]}")

        # Convert InvoiceDate to datetime
        df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')
        if df['InvoiceDate'].isna().sum() > 0:
            print(f"Warning: {df['InvoiceDate'].isna().sum()} rows with invalid dates were found.")

        # Calculate total order value
        df['TotalPrice'] = df['Quantity'] * df['UnitPrice']

        return df

    except Exception as e:
        print(f"Error in load_and_clean_data: {str(e)}")
        return None

def feature_engineering(df):
    """
    Engineer features for customer segmentation (RFM analysis).
    """
    try:
        if df is None or df.empty:
            raise ValueError("Input dataframe is empty or None")

        # Aggregate data by CustomerID
        customer_data = df.groupby('CustomerID').agg({
            'InvoiceNo': 'nunique',  # Purchase frequency
            'TotalPrice': 'mean',   # Average order value
            'Quantity': 'sum',      # Total items purchased
            'InvoiceDate': 'max'    # Last purchase date
        }).reset_index()

        # Rename columns for clarity
        customer_data.columns = ['CustomerID', 'PurchaseFrequency', 'AvgOrderValue', 'TotalItems', 'LastPurchase']

        # Calculate Recency (days since last purchase)
        max_date = df['InvoiceDate'].max()
        customer_data['Recency'] = (max_date - customer_data['LastPurchase']).dt.days

        # Remove outliers using IQR for AvgOrderValue
        Q1 = customer_data['AvgOrderValue'].quantile(0.25)
        Q3 = customer_data['AvgOrderValue'].quantile(0.75)
        IQR = Q3 - Q1
        initial_rows = customer_data.shape[0]
        customer_data = customer_data[
            (customer_data['AvgOrderValue'] >= Q1 - 1.5 * IQR) &
            (customer_data['AvgOrderValue'] <= Q3 + 1.5 * IQR)
        ]
        print(f"Rows after removing outliers: {customer_data.shape[0]} ({initial_rows - customer_data.shape[0]} rows dropped)")

        return customer_data

    except Exception as e:
        print(f"Error in feature_engineering: {str(e)}")
        return None

# File path for dataset uploaded directly to Colab
file_path = '/content/OnlineRetail.csv'

# Run data cleaning and preprocessing
df = load_and_clean_data(file_path)
if df is not None:
    customer_data = feature_engineering(df)
    if customer_data is not None:
        # Save the cleaned and engineered data
        output_path = '/content/cleaned_customer_data.csv'
        customer_data.to_csv(output_path, index=False)
        print(f"Cleaned data saved to: {output_path}")

        # Display summary
        print("\nCleaned Customer Data Summary:")
        print(customer_data.head())
        print("\nData Info:")
        print(customer_data.info())
    else:
        print("Feature engineering failed.")
else:
    print("Data loading and cleaning failed.")

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

def apply_clustering(data, n_clusters=4):
    # Select features for clustering
    features = ['PurchaseFrequency', 'AvgOrderValue', 'Recency']
    X = data[features]

    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Apply K-means clustering
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    data['Cluster'] = kmeans.fit_predict(X_scaled)

    # Visualize clusters
    plt.figure(figsize=(10, 6))
    plt.scatter(data['PurchaseFrequency'], data['AvgOrderValue'], c=data['Cluster'], cmap='viridis')
    plt.xlabel('Purchase Frequency')
    plt.ylabel('Average Order Value')
    plt.title('Customer Segments')
    plt.savefig('/content/clusters.png')
    plt.show()

    return data

# Run in Colab
customer_data = pd.read_csv('/content/cleaned_customer_data.csv')
clustered_data = apply_clustering(customer_data)
clustered_data.to_csv('/content/clustered_customer_data.csv', index=False)

import sqlite3
import pandas as pd

# Connect to SQLite database
conn = sqlite3.connect(':memory:')  # In-memory database for Colab
cursor = conn.cursor()

# Create table
cursor.execute("""
CREATE TABLE customer_segments (
    CustomerID INTEGER,
    PurchaseFrequency INTEGER,
    AvgOrderValue REAL,
    TotalItems INTEGER,
    Recency INTEGER,
    Cluster INTEGER
);
""")

# Load clustered data into SQLite
clustered_data = pd.read_csv('/content/clustered_customer_data.csv')
clustered_data.to_sql('customer_segments', conn, if_exists='replace', index=False)

# Execute query
query = """
SELECT
    Cluster,
    COUNT(DISTINCT CustomerID) AS CustomerCount,
    SUM(AvgOrderValue * PurchaseFrequency) AS TotalRevenue
FROM customer_segments
GROUP BY Cluster
ORDER BY TotalRevenue DESC;
"""
metrics = pd.read_sql_query(query, conn)
metrics.to_csv('/content/segment_metrics.csv', index=False)

# Display results
print(metrics)

# Close connection
conn.close()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

def create_visualizations(data):
    # Set style
    sns.set(style="whitegrid")

    # Boxplot for AvgOrderValue by Cluster
    plt.figure(figsize=(10, 6))
    sns.boxplot(x='Cluster', y='AvgOrderValue', data=data)
    plt.title('Average Order Value by Cluster')
    plt.savefig('/content/avg_order_value_by_cluster.png')
    plt.show()

    # Heatmap for feature correlations
    plt.figure(figsize=(8, 6))
    sns.heatmap(data[['PurchaseFrequency', 'AvgOrderValue', 'Recency']].corr(), annot=True, cmap='coolwarm')
    plt.title('Feature Correlations')
    plt.savefig('/content/correlation_heatmap.png')
    plt.show()

# Run in Colab
customer_data = pd.read_csv('/content/clustered_customer_data.csv')
create_visualizations(customer_data)

with open('/content/recommendations.md', 'w') as f:
    f.write("""# Customer Segmentation Analysis Report

Cluster Insights

  Cluster 0 (High-Value Customers): High AvgOrderValue, frequent purchases, low Recency. These are loyal customers who spend significantly.

  Cluster 1 (Frequent Low-Spenders): High PurchaseFrequency, low AvgOrderValue. These customers buy often but in smaller amounts.

  Cluster 2 (Churn Risk): High Recency, low PurchaseFrequency. These customers haven't purchased recently and may be at risk of churning.

  Cluster 3 (Occasional Spenders): Moderate AvgOrderValue, low PurchaseFrequency. These customers buy infrequently but spend moderately when they do.

Marketing Recommendations

  High-Value Customers (Cluster 0):

    Implement a loyalty program with exclusive discounts or early access to new products.

    Estimated revenue increase: 10-15% through increased retention.

  Frequent Low-Spenders (Cluster 1):

    Offer bundle deals or incentives for higher-value purchases to increase AvgOrderValue.

  Churn Risk (Cluster 2):

    Send personalized re-engagement emails with discounts or reminders.

  Occasional Spenders (Cluster 3):

    Use targeted ads to encourage more frequent purchases.

Next Steps

  Monitor segment performance quarterly.

  Test marketing campaigns and measure impact on revenue and retention.""")

from IPython.display import Markdown
with open('/content/recommendations.md', 'r') as f:
    display(Markdown(f.read()))

!pip install ipywidgets

import pandas as pd
import ipywidgets as widgets
from IPython.display import display, Image, Markdown
import matplotlib.pyplot as plt
import seaborn as sns

# Load data
data = pd.read_csv('/content/clustered_customer_data.csv')
metrics = pd.read_csv('/content/segment_metrics.csv')

# Create dropdown for selecting visualization
vis_options = ['Cluster Scatter Plot', 'Avg Order Value by Cluster', 'Correlation Heatmap']
dropdown = widgets.Dropdown(options=vis_options, description='Select Plot:')

# Output widget for displaying plots
output = widgets.Output()

def display_visualization(change):
    with output:
        output.clear_output()
        if change['new'] == 'Cluster Scatter Plot':
            display(Image('/content/clusters.png'))
        elif change['new'] == 'Avg Order Value by Cluster':
            display(Image('/content/avg_order_value_by_cluster.png'))
        elif change['new'] == 'Correlation Heatmap':
            display(Image('/content/correlation_heatmap.png'))

dropdown.observe(display_visualization, names='value')

# Display metrics
print("Segment Metrics:")
print(metrics)

# Display recommendations
with open('/content/recommendations.md', 'r') as f:
    display(Markdown(f.read()))

# Display dropdown and output
display(dropdown)
display(output)

!ls /content/

from google.colab import files

files.download('/content/cleaned_customer_data.csv')
files.download('/content/clustered_customer_data.csv')
files.download('/content/segment_metrics.csv')
files.download('/content/clusters.png')
files.download('/content/avg_order_value_by_cluster.png')
files.download('/content/correlation_heatmap.png')
files.download('/content/recommendations.md')