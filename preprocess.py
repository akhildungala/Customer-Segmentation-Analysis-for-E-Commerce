# -*- coding: utf-8 -*-
"""preprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17zFYpL5mzcSf2OYc9dldpeEBy21j1ILA
"""

# Check Python version
!python --version

# Install required libraries (if not already installed)
!pip install pandas numpy scikit-learn seaborn matplotlib

# Verify installations
import pandas as pd
import numpy as np
import sklearn
import seaborn as sns
import matplotlib
import sqlite3

print("Pandas version:", pd. __version__)
print("NumPy version:", np. __version__)
print("Scikit-learn version:", sklearn.__version__)
print("Seaborn version:", sns.__version__)
print("Matplotlib version:", matplotlib.__version__)
print("SQLite3 version:", sqlite3.sqlite_version)

# Load and preview the dataset
import pandas as pd

# Adjust the file path if necessary (e.g., if uploaded manually, itâ€™s in /content)
df = pd.read_csv('/content/OnlineRetail.csv', encoding='latin1')
df.head()  # Display the first 5 rows

import pandas as pd
import numpy as np
import os

def load_and_clean_data(file_path):
    """
    Load and clean the Online Retail dataset.
    """
    try:
        # Check if file exists
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Dataset file not found at: {file_path}")

        # Load dataset
        df = pd.read_csv(file_path, encoding='ISO-8859-1')
        print(f"Dataset loaded successfully. Shape: {df.shape}")

        # Handle missing values
        initial_rows = df.shape[0]
        df = df.dropna(subset=['CustomerID', 'InvoiceNo', 'Quantity', 'UnitPrice'])
        print(f"Rows after removing missing values: {df.shape[0]} ({initial_rows - df.shape[0]} rows dropped)")

        # Remove negative quantities and prices (likely errors or refunds)
        df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]
        print(f"Rows after removing negative quantities/prices: {df.shape[0]}")

        # Convert InvoiceDate to datetime
        df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')
        if df['InvoiceDate'].isna().sum() > 0:
            print(f"Warning: {df['InvoiceDate'].isna().sum()} rows with invalid dates were found.")

        # Calculate total order value
        df['TotalPrice'] = df['Quantity'] * df['UnitPrice']

        return df

    except Exception as e:
        print(f"Error in load_and_clean_data: {str(e)}")
        return None

def feature_engineering(df):
    """
    Engineer features for customer segmentation (RFM analysis).
    """
    try:
        if df is None or df.empty:
            raise ValueError("Input dataframe is empty or None")

        # Aggregate data by CustomerID
        customer_data = df.groupby('CustomerID').agg({
            'InvoiceNo': 'nunique',  # Purchase frequency
            'TotalPrice': 'mean',   # Average order value
            'Quantity': 'sum',      # Total items purchased
            'InvoiceDate': 'max'    # Last purchase date
        }).reset_index()

        # Rename columns for clarity
        customer_data.columns = ['CustomerID', 'PurchaseFrequency', 'AvgOrderValue', 'TotalItems', 'LastPurchase']

        # Calculate Recency (days since last purchase)
        max_date = df['InvoiceDate'].max()
        customer_data['Recency'] = (max_date - customer_data['LastPurchase']).dt.days

        # Remove outliers using IQR for AvgOrderValue
        Q1 = customer_data['AvgOrderValue'].quantile(0.25)
        Q3 = customer_data['AvgOrderValue'].quantile(0.75)
        IQR = Q3 - Q1
        initial_rows = customer_data.shape[0]
        customer_data = customer_data[
            (customer_data['AvgOrderValue'] >= Q1 - 1.5 * IQR) &
            (customer_data['AvgOrderValue'] <= Q3 + 1.5 * IQR)
        ]
        print(f"Rows after removing outliers: {customer_data.shape[0]} ({initial_rows - customer_data.shape[0]} rows dropped)")

        return customer_data

    except Exception as e:
        print(f"Error in feature_engineering: {str(e)}")
        return None

# File path for dataset uploaded directly to Colab
file_path = '/content/OnlineRetail.csv'

# Run data cleaning and preprocessing
df = load_and_clean_data(file_path)
if df is not None:
    customer_data = feature_engineering(df)
    if customer_data is not None:
        # Save the cleaned and engineered data
        output_path = '/content/cleaned_customer_data.csv'
        customer_data.to_csv(output_path, index=False)
        print(f"Cleaned data saved to: {output_path}")

        # Display summary
        print("\nCleaned Customer Data Summary:")
        print(customer_data.head())
        print("\nData Info:")
        print(customer_data.info())
    else:
        print("Feature engineering failed.")
else:
    print("Data loading and cleaning failed.")